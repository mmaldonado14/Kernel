{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3988b35-66a3-4f57-b0ca-970d34737e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx.enum.table import WD_TABLE_ALIGNMENT\n",
    "import feedparser\n",
    "\n",
    "# Fuentes RSS relevantes (puedes agregar más)\n",
    "RSS_FEEDS = [\n",
    "    \"https://news.google.com/rss/search?q=memorándum+de+entendimiento+Panamá+Estados+Unidos\",\n",
    "    \"https://www.prensa.com/rss/ultimas-noticias/\",\n",
    "    \"https://www.laestrella.com.pa/rss\",\n",
    "    \"https://feeds.bbci.co.uk/mundo/rss.xml\",\n",
    "]\n",
    "\n",
    "# Función para obtener país y medio de comunicación\n",
    "def get_source_info(entry):\n",
    "    if 'source' in entry:\n",
    "        medio = entry['source']['title']\n",
    "    elif 'title_detail' in entry:\n",
    "        medio = entry['title_detail']['base']\n",
    "    else:\n",
    "        medio = entry.get('link', '').split('/')[2] if 'link' in entry else 'Desconocido'\n",
    "    # País por heurística simple\n",
    "    if '.pa' in medio or 'panama' in medio:\n",
    "        pais = 'Panamá'\n",
    "    elif '.us' in medio or 'unitedstates' in medio or 'america' in medio:\n",
    "        pais = 'Estados Unidos'\n",
    "    elif '.mx' in medio or 'mexico' in medio:\n",
    "        pais = 'México'\n",
    "    elif '.es' in medio or 'spain' in medio:\n",
    "        pais = 'España'\n",
    "    elif '.uk' in medio or 'bbc' in medio:\n",
    "        pais = 'Reino Unido'\n",
    "    else:\n",
    "        pais = 'Internacional'\n",
    "    return medio, pais\n",
    "\n",
    "# Recopilar noticias\n",
    "noticias = []\n",
    "for feed_url in RSS_FEEDS:\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    for entry in feed.entries:\n",
    "        titulo = entry.title\n",
    "        link = entry.link\n",
    "        medio, pais = get_source_info(entry)\n",
    "        # Filtrar solo noticias relevantes\n",
    "        if 'memorándum' in titulo.lower() or 'memorandum' in titulo.lower():\n",
    "            noticias.append({\n",
    "                'titulo': titulo,\n",
    "                'medio': medio,\n",
    "                'pais': pais,\n",
    "                'link': link\n",
    "            })\n",
    "\n",
    "# Crear documento Word\n",
    "doc = Document()\n",
    "doc.add_heading('Reporte de Noticias: Memorándum de Entendimiento Panamá - Estados Unidos', 0)\n",
    "table = doc.add_table(rows=1, cols=3)\n",
    "table.alignment = WD_TABLE_ALIGNMENT.CENTER\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = 'Título de la Noticia'\n",
    "hdr_cells[1].text = 'Medio de Comunicación'\n",
    "hdr_cells[2].text = 'País'\n",
    "\n",
    "for noticia in noticias:\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = noticia['titulo']\n",
    "    row_cells[1].text = noticia['medio']\n",
    "    row_cells[2].text = noticia['pais']\n",
    "\n",
    "doc.add_paragraph(f'Total de noticias encontradas: {len(noticias)}')\n",
    "doc.save('Reporte_Memorandum_Panama_EEUU.docx')\n",
    "print(\"Reporte generado: Reporte_Memorandum_Panama_EEUU.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Argumentos de línea de comandos\n",
    "parser = agruparse.ArgumentParser(description='Script para importar datos desde archivos, base de datos y sitios web.')\n",
    "parser.add_argument('--archivo', type=str, help='Ruta al archivo CSV para importar')\n",
    "parser.add_argument('--db', type=str, help='Ruta a la base de datos SQLite')\n",
    "parser.add_argument('--url', type=str, help='URL de sitio web para importar datos')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Importar desde archivo CSV\n",
    "if args.archivo:\n",
    "    df_archivo = pd.read_csv(args.archivo)\n",
    "    print(\"Datos importados desde archivo:\", df_archivo.head())\n",
    "\n",
    "# Importar desde base de datos SQLite\n",
    "if args.db:\n",
    "    conn = sqlite3.connect(args.db)\n",
    "    df_db = pd.read_sql_query(\"SELECT * FROM noticias\", conn)\n",
    "    print(\"Datos importados desde base de datos:\", df_db.head())\n",
    "    conn.close()\n",
    "\n",
    "# Importar desde sitio web\n",
    "if args.url:\n",
    "    response = requests.get(args.url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    print(\"Contenido HTML importado desde sitio web:\", soup.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "¿Cómo se puede mejorar este script?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
